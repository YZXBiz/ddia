# 1. Trade-offs in Data Systems Architecture

_There are no solutions, there are only trade-offs. [...] But you try to get the best trade-off you can get, and that's all you can hope for._

â€” Thomas Sowell, Interview with Fred Barnes (2005)

---

**Previous:** [Table of Contents](README.md) | **Next:** [Chapter 2: Defining Nonfunctional Requirements](02-nonfunctional-requirements.md)

---

## Table of Contents

1. [Introduction to Data-Intensive Applications](#1-introduction-to-data-intensive-applications)
2. [Understanding System Building Blocks](#2-understanding-system-building-blocks)
3. [Analytical versus Operational Systems](#3-analytical-versus-operational-systems)
   - 3.1. [Transaction Processing vs Analytics](#31-transaction-processing-vs-analytics)
   - 3.2. [Data Warehousing Evolution](#32-data-warehousing-evolution)
   - 3.3. [From Data Warehouse to Data Lake](#33-from-data-warehouse-to-data-lake)
   - 3.4. [Systems of Record vs Derived Data](#34-systems-of-record-vs-derived-data)
4. [Cloud versus Self-Hosting](#4-cloud-versus-self-hosting)
   - 4.1. [The Build vs Buy Decision](#41-the-build-vs-buy-decision)
   - 4.2. [Cloud-Native Architecture](#42-cloud-native-architecture)
   - 4.3. [Operations in the Cloud Era](#43-operations-in-the-cloud-era)
5. [Distributed versus Single-Node Systems](#5-distributed-versus-single-node-systems)
   - 5.1. [When Distribution is Necessary](#51-when-distribution-is-necessary)
   - 5.2. [Problems with Distributed Systems](#52-problems-with-distributed-systems)
   - 5.3. [Microservices and Serverless](#53-microservices-and-serverless)
6. [Data Systems, Law, and Society](#6-data-systems-law-and-society)
7. [Summary](#7-summary)

---

## 1. Introduction to Data-Intensive Applications

**In plain English:** Modern applications are primarily challenged by data complexityâ€”storing, retrieving, and processing informationâ€”rather than raw computational power.

**In technical terms:** Data-intensive applications face challenges around managing large data volumes, ensuring consistency during failures and concurrency, and maintaining high availability.

**Why it matters:** Understanding the difference between data-intensive and compute-intensive systems guides architectural decisions and technology choices.

```
Traditional Computing Challenges    â†’    Modern Data System Challenges
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Limited CPU Power                      Massive Data Volumes
Memory Constraints                      Complex Data Relationships
Single Machine Processing              Distributed Data Management
Fixed Storage Capacity                  Real-time Processing Needs
```

Data is central to much application development today. With web and mobile apps, software as a service (SaaS), and cloud services, it has become normal to store data from many different users in a shared server-based data infrastructure. Data from user activity, business transactions, devices and sensors needs to be stored and made available for analysis.

### 1.1. Data Volume Complexity

Small amounts of data, which can be stored and processed on a single machine, are often fairly easy to deal with. However, as the data volume or the rate of queries grows, it needs to be distributed across multiple machines, which introduces many challenges.

> **ðŸ’¡ Insight**
>
> The transition from single-machine to distributed systems isn't just about scaleâ€”it's a fundamental shift in complexity. Each additional machine multiplies the potential failure modes and coordination challenges.

We call an application **data-intensive** if data management is one of the primary challenges in developing the application. While in compute-intensive systems the challenge is parallelizing some very large computation, in data-intensive applications we usually worry more about:

- **Storing and processing large data volumes**
- **Managing changes to data**
- **Ensuring consistency in the face of failures and concurrency**
- **Making sure services are highly available**

---

## 2. Understanding System Building Blocks

**In plain English:** Most applications are built by combining standard data system components like databases, caches, and search indexesâ€”like assembling LEGO blocks to create something more complex.

**In technical terms:** Applications typically integrate multiple specialized systems (databases, caches, search indexes, stream processors, batch processors) through application code that orchestrates their interaction.

**Why it matters:** Understanding these building blocks helps you choose the right tool for each job and architect systems that can evolve as requirements change.

Such applications are typically built from standard building blocks that provide commonly needed functionality:

```
Common Data System Building Blocks
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ“Š Databases          â†’ Store data for later retrieval
ðŸš€ Caches            â†’ Speed up expensive operations
ðŸ” Search Indexes     â†’ Enable keyword/filter queries
âš¡ Stream Processing  â†’ Handle real-time events
ðŸ“ˆ Batch Processing   â†’ Crunch large data volumes periodically
```

### 2.1. The Integration Challenge

In building an application we typically take several software systems or services, such as databases or APIs, and glue them together with some application code. If you are doing exactly what the data systems were designed for, then this process can be quite easy.

However, as your application becomes more ambitious, challenges arise:

- **How do you choose which database to use?** Different databases have different characteristics and are suitable for different purposes.
- **How do you reason about trade-offs?** Various approaches to caching, indexing, etc. each have pros and cons.
- **How do you combine tools** when no single tool can handle all requirements?

> **ðŸ’¡ Insight**
>
> The art of system architecture lies not in picking perfect tools (they don't exist), but in understanding trade-offs and composing imperfect tools into systems that meet your specific requirements.

This book is a guide to help you make decisions about which technologies to use and how to combine them. As you will see, there is no one approach that is fundamentally better than others; everything has pros and cons.

---

## 3. Analytical versus Operational Systems

**In plain English:** Think of the difference between a cash register (operational) and a business analyst reviewing sales reports (analytical). Same data, completely different usage patterns and requirements.

**In technical terms:** Operational systems serve real-time user requests with point queries and updates, while analytical systems perform complex aggregations over large datasets for business intelligence.

**Why it matters:** These different usage patterns require fundamentally different architectures, data layouts, and optimization strategies.

```
Data Usage Patterns in Organizations
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Operational Systems                     Analytical Systems
      â†“                                       â†“
[User clicks buy]                      [Analyst asks: "What
[Update inventory]          â†’          were our top-selling
[Process payment]                      products last month?"]
[Send confirmation]                           â†“
      â†“                                [Query millions of
[Point queries]                        transaction records]
[Real-time updates]                    [Generate report]
```

If you are working on data systems in an enterprise, you will encounter several different types of people who work with data:

1. **Backend engineers** who build services handling user requests
2. **Business analysts** who generate reports for management decisions
3. **Data scientists** who look for insights and create ML-powered features

### 3.1. Transaction Processing vs Analytics

The distinction between operational and analytical systems has led to specialized terminology and architectures:

**Online Transaction Processing (OLTP)**
- Handles interactive user requests
- Point queries (lookup individual records by key)
- Create, update, delete individual records
- Fixed set of queries predefined by application
- Current state of data
- Dataset size: Gigabytes to Terabytes

**Online Analytical Processing (OLAP)**
- Handles business intelligence queries
- Aggregate over large number of records
- Bulk import (ETL) or event streams
- Analysts can make arbitrary queries
- Historical events over time
- Dataset size: Terabytes to Petabytes

| Property | Operational Systems (OLTP) | Analytical Systems (OLAP) |
|----------|---------------------------|---------------------------|
| **Main read pattern** | Point queries (fetch individual records by key) | Aggregate over large number of records |
| **Main write pattern** | Create, update, and delete individual records | Bulk import (ETL) or event stream |
| **Human user example** | End user of web/mobile application | Internal analyst, for decision support |
| **Machine use example** | Checking if an action is authorized | Detecting fraud/abuse patterns |
| **Type of queries** | Fixed set of queries, predefined by application | Analyst can make arbitrary queries |
| **Data represents** | Latest state of data (current point in time) | History of events that happened over time |
| **Dataset size** | Gigabytes to terabytes | Terabytes to petabytes |

### 3.2. Data Warehousing Evolution

**In plain English:** A data warehouse is like a specialized library for business dataâ€”it takes information from all the different operational systems and organizes it in a way that's optimized for analysis rather than day-to-day operations.

**In technical terms:** A data warehouse is a separate analytical database containing read-only copies of data from operational systems, optimized for aggregate queries rather than transactional workloads.

**Why it matters:** Separating analytical and operational workloads prevents analytics queries from impacting production performance while enabling specialized optimizations for each use case.

At first, the same databases were used for both transaction processing and analytic queries. However, in the late 1980s and early 1990s, there was a trend for companies to run analytics on a separate database systemâ€”the **data warehouse**.

#### Why Separate Analytics from Operations?

It is usually undesirable for business analysts to directly query OLTP systems for several reasons:

1. **Data silos**: Data of interest may be spread across multiple operational systems
2. **Schema mismatch**: OLTP schemas aren't optimized for analytics
3. **Performance impact**: Expensive analytic queries would slow down operational systems
4. **Security/compliance**: OLTP systems may be in separate networks

```
ETL Process Flow
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Operational Systems          Data Warehouse
      â†“                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web App DB â”‚              â”‚   Sales     â”‚
â”‚  POS System â”‚    â”Œâ”€â”€â”€â”     â”‚ Analytics   â”‚
â”‚  CRM System â”‚â”€â”€â”€â†’â”‚ETLâ”‚â”€â”€â”€â”€â†’â”‚   Schema    â”‚
â”‚ Supply Chainâ”‚    â””â”€â”€â”€â”˜     â”‚ Optimized   â”‚
â”‚   System    â”‚              â”‚ for Queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†‘                             â†‘
Transactional                Analytical
Processing                   Processing
```

#### Extractâ€“Transformâ€“Load (ETL)

The data warehouse contains a read-only copy of the data from operational systems. Data flows through an **ETL** process:

- **Extract**: Get data from OLTP databases (periodic dumps or continuous streams)
- **Transform**: Convert to analysis-friendly schema and clean up
- **Load**: Insert into the data warehouse

Sometimes the order is swapped to **ELT** (Extractâ€“Loadâ€“Transform), where transformation happens in the warehouse after loading.

### 3.3. From Data Warehouse to Data Lake

**In plain English:** If a data warehouse is like a well-organized library with books sorted by category, a data lake is like a massive storage room where you keep everythingâ€”books, magazines, videos, audio recordingsâ€”in their original format until you need them.

**In technical terms:** A data lake is a centralized repository that stores raw data in its native format (files, images, sensor data, etc.) without requiring a predefined schema, offering more flexibility than structured data warehouses.

**Why it matters:** Data lakes enable data scientists to work with diverse data types and perform custom transformations, but require more sophisticated tooling to extract value.

A data warehouse often uses a relational data model queried through SQL, but this is less suited to data science tasks such as:

- **Feature engineering** for machine learning models
- **Natural language processing** on textual data
- **Computer vision** on images

Many data scientists prefer Python (pandas, scikit-learn), R, or distributed frameworks like Spark rather than SQL databases.

#### The Data Lake Approach

A **data lake** is a centralized repository that:
- Holds any data that might be useful for analysis
- Contains files without imposing particular formats or data models
- Can store text, images, videos, sensor readings, feature vectors, etc.
- Uses commoditized file storage (often cheaper than relational storage)

```
Data Lake Architecture
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Raw Data Sources          Data Lake           Consumers
      â†“                      â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚         â”‚    Files    â”‚   â”‚   Python    â”‚
â”‚    Logs     â”‚         â”‚   Images    â”‚   â”‚ Data Scienceâ”‚
â”‚  Sensor     â”‚   â”€â”€â”€â†’  â”‚   Videos    â”‚â”€â”€â†’â”‚     R       â”‚
â”‚   Data      â”‚         â”‚   JSON      â”‚   â”‚   Spark     â”‚
â”‚  Database   â”‚         â”‚  Parquet    â”‚   â”‚ Notebooks   â”‚
â”‚  Exports    â”‚         â”‚    Avro     â”‚   â”‚  Tableau    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### The Sushi Principle

ETL processes have been generalized to **data pipelines**, and the data lake often serves as an intermediate stop containing "raw" data without transformation. This approach has been dubbed the **sushi principle**: "raw data is better" because each consumer can transform it to suit their specific needs.

### 3.4. Systems of Record vs Derived Data

**In plain English:** Think of a bank's core account balance system (system of record) versus the monthly statement you receive (derived data). If there's ever a discrepancy, the core system is always considered correct.

**In technical terms:** Systems of record hold the authoritative version of data where facts are represented exactly once, while derived data systems contain processed, cached, or transformed versions that can be recreated from the original source.

**Why it matters:** Understanding this distinction clarifies data flow and helps you design systems where it's clear which data is authoritative and which can be safely regenerated.

Related to the operational/analytical distinction, this book distinguishes between:

#### Systems of Record
- **Definition**: Source of truth holding authoritative/canonical data
- **Characteristics**: New data is written here first; each fact represented exactly once
- **Rule**: If there's discrepancy with another system, the system of record is correct

#### Derived Data Systems
- **Definition**: Result of processing data from other systems
- **Characteristics**: Can be recreated if lost; often redundant but essential for performance
- **Examples**: Caches, indexes, materialized views, ML models, transformed datasets

```
Data System Relationships
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

System of Record              Derived Data Systems
      â†“                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Posts  â”‚              â”‚   Search    â”‚
â”‚ Database    â”‚     â”€â”€â”€â†’     â”‚   Index     â”‚
â”‚ (Original   â”‚              â”‚ (Derived)   â”‚
â”‚  Content)   â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â†“
      â†“                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ Analytics   â”‚
                             â”‚ Warehouse   â”‚
                             â”‚ (Derived)   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **ðŸ’¡ Insight**
>
> Most databases can be either systems of record OR derived systemsâ€”it's not about the technology, it's about how you use it. A clear understanding of which data derives from which helps prevent architectural confusion.

Analytical systems are usually derived data systems because they consume data created elsewhere. Operational services may contain both systems of record (primary databases) and derived systems (indexes and caches for performance).

---

## 4. Cloud versus Self-Hosting

**In plain English:** This is like deciding whether to cook at home or eat at a restaurant. Home cooking gives you complete control but requires more effort; restaurants are convenient but you're at their mercy for menu changes and quality.

**In technical terms:** Organizations must decide whether to build and operate their own infrastructure or outsource to cloud providers, balancing control, cost, expertise requirements, and operational overhead.

**Why it matters:** This fundamental architectural decision affects everything from development speed to long-term costs to data sovereignty and system customization capabilities.

With anything an organization needs to do, one of the first questions is: **should it be done in-house, or outsourced?** Should you build or buy?

### 4.1. The Build vs Buy Decision

```
Software Deployment Spectrum
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Bespoke           Self-hosted        Managed         SaaS
In-house          Open Source        Cloud           Products
   â†“                 â†“               Service            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Custom  â”‚      â”‚ MySQL   â”‚      â”‚ AWS RDS â”‚      â”‚ Salesforce
â”‚ Code    â”‚      â”‚ on VMs  â”‚      â”‚ MongoDB â”‚      â”‚ Office 365
â”‚ & Ops   â”‚      â”‚ Your    â”‚      â”‚ Atlas   â”‚      â”‚ GitHub   â”‚
â”‚         â”‚      â”‚ Hardwareâ”‚      â”‚         â”‚      â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†‘               â†‘               â†‘               â†‘
Complete         Full Control    Managed Ops     Zero Ops
Control          Some Ops       Less Control    Vendor Lock
High Effort      Medium Effort   Lower Effort    Lowest Effort
```

The received management wisdom is that:
- **Core competencies** should be done in-house
- **Non-core, routine tasks** should be outsourced to vendors

#### Pros and Cons of Cloud Services

**Advantages:**
- **Faster time to market** if you lack operational expertise
- **Variable cost scaling** matches resource usage to demand
- **Specialized expertise** from providers focused on that service
- **Reduced operational overhead** for your team

**Disadvantages:**
- **No control over features** - can only request, not implement
- **No control over availability** - you wait when it's down
- **Limited debugging** - less visibility into performance issues
- **Vendor lock-in** risk if no compatible alternatives exist
- **Security/compliance** requires trusting the provider

> **ðŸ’¡ Insight**
>
> Cloud vs self-hosting isn't just a technical decisionâ€”it's a business strategy decision that affects your organization's capabilities, dependencies, and long-term flexibility.

### 4.2. Cloud-Native Architecture

**In plain English:** Instead of just moving your existing applications to run on cloud virtual machines, cloud-native means redesigning them to take advantage of cloud services as building blocksâ€”like using cloud storage, databases, and messaging services rather than managing your own.

**In technical terms:** Cloud-native architecture leverages managed cloud services as foundational building blocks rather than just running traditional software on cloud virtual machines, enabling better scalability, reliability, and operational efficiency.

**Why it matters:** Cloud-native systems can achieve better performance, faster recovery, and easier scaling than traditional applications simply moved to the cloud, but require different architectural patterns.

The term **cloud-native** describes architecture designed from the ground up to take advantage of cloud services.

#### Layering of Cloud Services

```
Cloud Service Abstraction Layers
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Higher Level
Services           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†‘              â”‚   Snowflake     â”‚
    â”‚              â”‚   BigQuery      â”‚
    â”‚              â”‚   Analytics     â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                      â†‘
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚   S3 Storage    â”‚
Platform           â”‚   Managed DBs   â”‚
Services           â”‚   Event Streams â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                      â†‘
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Infrastructure     â”‚  Virtual Machinesâ”‚
Services           â”‚  Network/Securityâ”‚
    â†“              â”‚  Block Storage   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Examples by Category:**

| Category | Self-hosted Systems | Cloud-native Systems |
|----------|-------------------|-------------------|
| **Operational/OLTP** | MySQL, PostgreSQL, MongoDB | AWS Aurora, Azure SQL DB Hyperscale, Google Cloud Spanner |
| **Analytical/OLAP** | Teradata, ClickHouse, Spark | Snowflake, Google BigQuery, Azure Synapse Analytics |

#### Separation of Storage and Compute

Cloud-native systems typically separate storage and compute responsibilities:

- **Traditional**: Same computer handles both storage (disk) and computation (CPU/RAM)
- **Cloud-native**: Storage services (S3) separate from compute services
- **Implication**: Data must transfer over network for processing

```
Traditional vs Cloud-Native Architecture
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Traditional Architecture    Cloud-Native Architecture
        â†“                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Server      â”‚              â”‚  Compute    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  Service    â”‚
â”‚  â”‚    CPU    â”‚  â”‚              â”‚  (Stateless)â”‚
â”‚  â”‚   Memory  â”‚  â”‚       â†â”€â”€â”€â”€â”€â”€â”‚             â”‚
â”‚  â”‚   Disk    â”‚  â”‚        Data  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚   Data    â”‚  â”‚      Transfer       â†‘
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†‘                         â”‚  Storage    â”‚
   Fixed Coupling                â”‚  Service    â”‚
                                 â”‚   (S3)      â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â†‘
                                 Separate Services
```

### 4.3. Operations in the Cloud Era

**In plain English:** The cloud hasn't eliminated the need for operationsâ€”it's changed what operations teams focus on. Instead of managing individual servers, they now manage services, integration, costs, and application reliability.

**In technical terms:** Operations has shifted from machine-level management (disk space, patches, hardware) to service-level management (API integration, cost optimization, monitoring, automation).

**Why it matters:** Understanding this shift helps you staff and organize operations teams appropriately for cloud environments while avoiding the myth that cloud means "no ops."

Traditional operations involved:
- **Capacity planning** (monitoring disk space, adding resources)
- **Machine provisioning** and maintenance
- **Operating system** patches and updates
- **Individual server** management

#### DevOps/SRE Philosophy

Modern cloud operations emphasizes:

```
Operations Evolution
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Traditional Ops â†’ Cloud Era Ops
      â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manual      â”‚   â”‚ Automated   â”‚
â”‚ Processes   â”‚   â”‚ Processes   â”‚
â”‚             â”‚   â”‚             â”‚
â”‚ Long-lived  â”‚   â”‚ Ephemeral   â”‚
â”‚ Servers     â”‚   â”‚ Resources   â”‚
â”‚             â”‚   â”‚             â”‚
â”‚ Infrequent  â”‚   â”‚ Frequent    â”‚
â”‚ Updates     â”‚   â”‚ Updates     â”‚
â”‚             â”‚   â”‚             â”‚
â”‚ Machine     â”‚   â”‚ Service     â”‚
â”‚ Focus       â”‚   â”‚ Focus       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Automation** over manual processes
2. **Ephemeral resources** over long-running servers
3. **Frequent updates** with reliable rollback
4. **Learning from incidents** and improving systems
5. **Knowledge preservation** as people change roles

#### New Operational Challenges

Even with cloud services, operations still requires:
- **Service selection** and integration
- **Cost optimization** (capacity planning becomes financial planning)
- **Security management** of applications and dependencies
- **Performance monitoring** and troubleshooting
- **Service orchestration** and workflow management

> **ðŸ’¡ Insight**
>
> Cloud computing doesn't eliminate operationsâ€”it elevates the level of abstraction. Teams shift from managing infrastructure to managing services, but the need for operational excellence remains critical.

---

## 5. Distributed versus Single-Node Systems

**In plain English:** A single-node system is like a talented individual working aloneâ€”fast, efficient, but limited by what one person can do. A distributed system is like a teamâ€”it can handle much more work, but coordination becomes a major challenge.

**In technical terms:** Distributed systems involve multiple machines communicating over a network to achieve goals that exceed single-machine capabilities, but introduce complex failure modes, consistency challenges, and performance trade-offs.

**Why it matters:** Distribution adds significant complexity, so it should be adopted only when the benefits clearly outweigh the costsâ€”many problems can still be solved effectively on a single powerful machine.

A **distributed system** involves several machines communicating via a network. Each participating process is called a **node**.

### 5.1. When Distribution is Necessary

There are various reasons to build distributed systems:

```
Reasons for Distribution
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Inherent Distribution    Technical Requirements
        â†“                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Multiple Users  â”‚        â”‚ Fault Tolerance â”‚
â”‚ Multiple Devicesâ”‚        â”‚ Scalability     â”‚
â”‚ Cloud Services  â”‚        â”‚ Low Latency     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ Elasticity      â”‚
        â†“                  â”‚ Specialized HW  â”‚
Business Requirements      â”‚ Compliance      â”‚
        â†“                  â”‚ Sustainability  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Geographic      â”‚                â†‘
â”‚ Distribution    â”‚         Operational Benefits
â”‚ Data Residency  â”‚
â”‚ Compliance      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Technical Reasons:
1. **Fault tolerance/high availability** - redundancy across machines
2. **Scalability** - handle load beyond single machine capacity
3. **Latency** - serve users from geographically close servers
4. **Elasticity** - scale resources up/down with demand
5. **Specialized hardware** - different workloads on optimal hardware

#### Business Reasons:
6. **Legal compliance** - data residency requirements
7. **Sustainability** - run workloads when/where renewable energy is available

#### Inherent Reasons:
8. **Multiple users/devices** - unavoidably requires network communication
9. **Cloud services** - data stored separately from processing

### 5.2. Problems with Distributed Systems

**In plain English:** Every network call can fail, timeout, or return partial results, and you often can't tell the difference between a slow response and a failed request. This uncertainty makes distributed systems fundamentally more complex than single-machine programs.

**In technical terms:** Distributed systems must handle network failures, partial failures, timing issues, and consistency challenges that don't exist in single-node systems, requiring sophisticated protocols and careful system design.

**Why it matters:** These challenges aren't edge casesâ€”they're fundamental characteristics that must be designed around from the beginning. Ignoring them leads to data loss and system failures.

Distribution introduces several fundamental challenges:

```
Distributed System Challenges
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Network Issues          Performance Issues
      â†“                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Timeouts    â”‚          â”‚ Network     â”‚
â”‚ Failures    â”‚          â”‚ Latency     â”‚
â”‚ Retries     â”‚          â”‚ Bandwidth   â”‚
â”‚ Partitions  â”‚          â”‚ Limits      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                        â†“
Reliability Issues      Consistency Issues
      â†“                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partial     â”‚          â”‚ Data Sync   â”‚
â”‚ Failures    â”‚          â”‚ Conflicts   â”‚
â”‚ Node Crashesâ”‚          â”‚ Ordering    â”‚
â”‚ Recovery    â”‚          â”‚ Updates     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Challenges:

1. **Network failures**: Requests can timeout without knowing if they succeeded
2. **Performance overhead**: Network calls are much slower than local function calls
3. **Debugging complexity**: Hard to identify where problems originate
4. **Data consistency**: Maintaining consistency across services becomes application's problem
5. **Observability needs**: Require sophisticated tracing and monitoring tools

> **ðŸ’¡ Insight**
>
> The fundamental challenge of distributed systems isn't technicalâ€”it's epistemological. You often can't know whether a remote operation succeeded, failed, or is still in progress, and you must design around this uncertainty.

#### When Single-Node is Better

```
Single-Node Advantages
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Simplicity Benefits
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ No Network      â”‚
â”‚ Failures        â”‚
â”‚                 â”‚
â”‚ Local Function  â”‚
â”‚ Calls           â”‚
â”‚                 â”‚
â”‚ Easier Debug    â”‚
â”‚                 â”‚
â”‚ ACID Guarantees â”‚
â”‚                 â”‚
â”‚ Lower Cost      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**If you can do something on a single machine, it's often much simpler and cheaper** than distributed systems. Modern single-node systems are surprisingly capable:

- CPUs, memory, and disks have grown larger, faster, and more reliable
- Single-node databases like DuckDB, SQLite, and KÃ¹zuDB handle many workloads
- Sometimes a single-threaded program outperforms a 100+ CPU cluster

### 5.3. Microservices and Serverless

**In plain English:** Microservices is like organizing a company into small, independent teams where each team handles one specific business function. Each team can work at their own pace, but coordination between teams becomes a major challenge.

**In technical terms:** Microservices architecture decomposes applications into small, independently deployable services that communicate over well-defined APIs, enabling team autonomy but requiring sophisticated operational infrastructure.

**Why it matters:** Microservices solve organizational problems (team coordination) but introduce technical complexity. They're valuable for large organizations but may be unnecessary overhead for small teams.

#### Microservices Architecture

The most common distributed system pattern divides applications into **clients and servers** communicating via HTTP APIs.

```
Microservices Architecture
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Monolith â†’ Microservices Decomposition
    â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Single    â”‚   â”‚   User      â”‚ â”‚   Order     â”‚
â”‚ Application â”‚   â”‚  Service    â”‚ â”‚  Service    â”‚
â”‚             â”‚â”€â”€â†’â”‚             â”‚â”€â”‚             â”‚
â”‚ - Users     â”‚   â”‚ - Profile   â”‚ â”‚ - Cart      â”‚
â”‚ - Orders    â”‚   â”‚ - Auth      â”‚ â”‚ - Payment   â”‚
â”‚ - Inventory â”‚   â”‚ - Sessions  â”‚ â”‚ - Shipping  â”‚
â”‚ - Payments  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â†‘              â†‘
                         â”‚              â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Inventory   â”‚ â”‚  Payment    â”‚
                   â”‚  Service    â”‚ â”‚  Service    â”‚
                   â”‚             â”‚ â”‚             â”‚
                   â”‚ - Stock     â”‚ â”‚ - Billing   â”‚
                   â”‚ - Supply    â”‚ â”‚ - Receipts  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Advantages:**
- **Independent deployment** reduces coordination between teams
- **Resource allocation** can be optimized per service
- **Implementation hiding** behind APIs enables internal changes
- **Database isolation** prevents cross-service performance impact

**Disadvantages:**
- **Infrastructure complexity** for each service (deployment, monitoring, logging)
- **Testing complexity** requires running dependent services
- **API evolution challenges** when clients expect certain fields
- **Network overhead** for inter-service communication

#### Serverless/Function-as-a-Service (FaaS)

```
Serverless Evolution
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Virtual Machines â†’ Containers â†’ Functions
       â†“               â†“           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manual      â”‚ â”‚ Container   â”‚ â”‚ Auto-scalingâ”‚
â”‚ Scaling     â”‚ â”‚ Orchestrationâ”‚ â”‚ Functions   â”‚
â”‚             â”‚ â”‚ (Kubernetes)â”‚ â”‚             â”‚
â”‚ Always-on   â”‚ â”‚ Defined     â”‚ â”‚ Pay-per-use â”‚
â”‚ Billing     â”‚ â”‚ Resources   â”‚ â”‚ Billing     â”‚
â”‚             â”‚ â”‚             â”‚ â”‚             â”‚
â”‚ Server      â”‚ â”‚ Less Server â”‚ â”‚ "Serverless"â”‚
â”‚ Management  â”‚ â”‚ Management  â”‚ â”‚ Management  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Serverless** brings metered billing to code executionâ€”you only pay for actual runtime rather than provisioned resources.

**Benefits:**
- **Automatic scaling** based on demand
- **Usage-based billing** reduces idle resource costs
- **Operational simplicity** for simple functions

**Limitations:**
- **Execution time limits** for long-running processes
- **Cold start latency** when functions haven't run recently
- **Runtime environment restrictions**

> **ðŸ’¡ Insight**
>
> Microservices are primarily a solution to organizational challenges, not technical ones. They enable team independence but require significant operational investment. Consider your organization's size and structure when deciding.

---

## 6. Data Systems, Law, and Society

**In plain English:** Building data systems isn't just about technical requirementsâ€”you have legal and ethical responsibilities to the people whose data you're handling. Privacy laws like GDPR fundamentally change how systems must be designed.

**In technical terms:** Legal requirements like data deletion rights, residency requirements, and consent management must be considered as first-class architectural constraints, not afterthoughts, influencing fundamental design decisions.

**Why it matters:** Legal non-compliance can result in massive fines and reputational damage. More importantly, data systems affect people's lives and society, creating ethical responsibilities for engineers.

Data systems architecture is influenced not only by technical goals, but also by human needs and legal requirements.

### 6.1. Privacy Regulation Impact

Since 2018, the **General Data Protection Regulation (GDPR)** has given European residents greater control over their personal data. Similar laws exist worldwide:
- **California Consumer Privacy Act (CCPA)**
- **EU AI Act** for artificial intelligence systems
- Various national data residency requirements

```
Legal Requirements vs Technical Challenges
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Legal Right               Technical Challenge
     â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Right to    â”‚           â”‚ Delete from     â”‚
â”‚ Erasure     â”‚    â”€â”€â†’    â”‚ Immutable Logs? â”‚
â”‚             â”‚           â”‚                 â”‚
â”‚ Data        â”‚           â”‚ Remove from ML  â”‚
â”‚ Portability â”‚    â”€â”€â†’    â”‚ Training Data?  â”‚
â”‚             â”‚           â”‚                 â”‚
â”‚ Consent     â”‚           â”‚ Retroactive     â”‚
â”‚ Withdrawal  â”‚    â”€â”€â†’    â”‚ Data Cleanup?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Engineering Challenges from Legal Requirements

**Right to be Forgotten:**
- How to delete data from immutable append-only logs?
- How to remove data from derived datasets and ML models?
- How to propagate deletions through data pipelines?

**Data Minimization:**
- Collecting only data necessary for specific purposes
- Automatic expiration of data when no longer needed
- Counter to "big data" philosophy of speculative storage

### 6.2. Risk-Based Decision Making

The costs of data storage include more than infrastructure bills:

```
Total Cost of Data Storage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Direct Costs          Hidden Costs
     â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 Bills    â”‚      â”‚ Legal Fines â”‚
â”‚ Compute     â”‚      â”‚ Breach Costsâ”‚
â”‚ Personnel   â”‚      â”‚ Compliance  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ Overhead    â”‚
                     â”‚ Reputation  â”‚
                     â”‚ Risk        â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Risk Factors:**
- **Security breaches** and data compromises
- **Legal liability** from non-compliant processing
- **Reputational damage** from privacy violations
- **User safety risks** in jurisdictions where data reveals criminalized behavior

> **ðŸ’¡ Insight**
>
> Sometimes the best architectural decision is not to store data at all. The principle of data minimization (Datensparsamkeit) often reduces both technical complexity and legal risk.

### 6.3. Compliance Frameworks

**Industry Standards:**
- **PCI DSS** for payment processing
- **SOC 2** for service organizations
- **HIPAA** for healthcare data
- **SOX** for financial reporting

These frameworks require:
- Regular third-party audits
- Documentation of data handling procedures
- Incident response capabilities
- Data encryption and access controls

---

## 7. Summary

This chapter introduced fundamental trade-offs in data system architecture. Key takeaways:

### 7.1. Core Distinctions

**Operational vs Analytical Systems:**
- Different access patterns require different architectures
- OLTP: Point queries, real-time updates, current state
- OLAP: Aggregations, bulk loads, historical analysis
- ETL pipelines connect operational systems to data warehouses/lakes

**Systems of Record vs Derived Data:**
- Authoritative data vs processed/cached data
- Clear data lineage prevents architectural confusion
- Derived systems can be recreated if lost

### 7.2. Deployment Decisions

**Cloud vs Self-Hosting:**
- Trade-off between control and operational overhead
- Cloud-native architectures separate storage and compute
- Operations role shifts from machines to services

**Distributed vs Single-Node:**
- Distribution adds complexity; avoid unless necessary
- Modern single-node systems are surprisingly powerful
- Microservices solve organizational problems but require operational investment

### 7.3. Legal and Ethical Considerations

**Compliance as Architecture:**
- Legal requirements must be first-class design constraints
- Privacy regulations change how systems are built
- Data minimization reduces both risk and complexity

> **ðŸ’¡ Insight**
>
> The recurring theme is that there are no perfect solutions, only trade-offs. Successful architecture requires understanding these trade-offs and choosing the set that best serves your specific requirements, constraints, and organizational context.

---

**Previous:** [Table of Contents](README.md) | **Next:** [Chapter 2: Defining Nonfunctional Requirements](02-nonfunctional-requirements.md)

---

_Understanding trade-offs is the foundation of good system architecture_